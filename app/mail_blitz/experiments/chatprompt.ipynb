{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mail_generation(model, context):\n",
    "    # Function to generate a promotional mail based on a given context using a language model\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", \"You are a telecommunication company agent and your job is to prevent customers from \\\n",
    "                                                churning by generating promotional mails without allowing them to know you know they have plans \\\n",
    "                                                of leaving You may be asked to generate a mail given a context.\" ),\n",
    "                                               (\"user\", \"{mail_description}\")],)\n",
    "    \n",
    "    output = model.invoke(prompt.format(mail_description=context))\n",
    "    return output\n",
    "\n",
    "def mail_revamp(model, mail, suggestion):\n",
    "    # Function to suggest corrections and revamp a generated mail\n",
    "    prompt = PromptTemplate(input_variables= [\"mail\", \"suggestion\"], \n",
    "                            template = \"You are a telecommunication company agent and your job is to revamp the promotional mails to be sent to the customers. \\\n",
    "                            Revamp this mail {mail} based on these suggested {suggestion} correction only. Don't go beyond the corrections requested\")\n",
    "    \n",
    "    output = model.invoke(prompt.format(mail = mail, suggestion = suggestion))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"You are a telecommunication company agent and your job is to prevent customers from churning by generating promotional\\\n",
    "      mails without allowing them to know you know they have plans of leaving. You may be asked to generate a mail given a context,\\\n",
    "         you can also be asked to revamp a given mail. In any case you are required to stay in your limit do not give suggestion except prompted to\" \n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "context = \"Generate a mail for a customer that is likely to leave the company's product. We have some good network upgrade coming to his/her location that may help change his mind\"\n",
    "\n",
    "output = mail_generation(llm, text, context)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a telecommunication company chatbot and your job is to generating promotional mails. \\\n",
    "        Your goal is to converse with an agent and list suject ideas for promotional mail.\n",
    "        If an option is selected, generate a promotional mail for the customer based on the suggestion from our agent, \\\n",
    "        ask for corrections and revamp the mail solely on this corrections if any.\n",
    "\n",
    "        {chat_history}\n",
    "        Human: {human_input}\n",
    "        \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"human_input\"],\n",
    "                        template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm_chain = LLMChain(\n",
    "                    llm = ChatOpenAI(),\n",
    "                    prompt = prompt,\n",
    "                    memory = memory,\n",
    "                    verbose = False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.invoke(\"Hello\")\n",
    "\n",
    "out = llm_chain.invoke(\"I need ideas on mail i can generate for a very good customer showing signs of leaving\")\n",
    "print(out['chat_history'])\n",
    "\n",
    "out = llm_chain.invoke(\"Yes! Generate a mail on the fourth suggestion\")\n",
    "print(out['chat_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a chatbot and your job is to generate promotional mail subject ideas for the company while \\\n",
    "                having a chat for the agent. Ask if the idea is fine and ask which option is fine after all conversation\"\"\"\n",
    "\n",
    "history = [HumanMessage(content = \"Hello\"), \n",
    "           AIMessage(content=\"Hello! How may i help you?\")]\n",
    "\n",
    "\n",
    "def mail_revamp(model, context, history):\n",
    "    # Function to suggest corrections and revamp a generated mail\n",
    "    prompt = ChatPromptTemplate.from_messages([(\"system\", template), \n",
    "                                               (\"placeholder\", \"{history}\"), \n",
    "                                               (\"user\", \"{input_text}\")])\n",
    "    \n",
    "    output = model.invoke(prompt.format(history = history, input_text= context))\n",
    "    return output\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "satisfied = 0\n",
    "while not satisfied:\n",
    "\n",
    "    context = \"Promotional mail ideas please?\"\n",
    "    history.append(HumanMessage(content=context))\n",
    "    output = mail_revamp(llm, context, history)\n",
    "    \n",
    "print(output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
