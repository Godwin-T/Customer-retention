{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import hp, STATUS_OK, fmin, Trials, tpe\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('sqlite:///../../databases/mlflow.db')\n",
    "mlflow.set_experiment('Customer_Churn_Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/churn-data/data/processed_data/churn.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "y = data['churn']\n",
    "X = data.drop(['churn'], axis=1)\n",
    "X = X.to_dict(orient=\"record\")\n",
    "\n",
    "\n",
    "(train_x, test_x, \n",
    "    train_y, test_y) = train_test_split(X, y, test_size= 0.3, random_state=1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)\n",
    "\n",
    "    out = {\"accuracy_score\" : accuracy, \n",
    "            \"precision_score\" :precision, \n",
    "            \"recall_score\" : recall, \n",
    "            \"f1_score\" : f1score}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "c_values = range(1, 50, 5)\n",
    "for val in c_values:\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('model', 'Logistic Regression')\n",
    "        mlflow.log_param('C', val)\n",
    "\n",
    "        lr_pipeline = make_pipeline(DictVectorizer(sparse= False),\n",
    "                                    LogisticRegression(C =val))\n",
    "        lr_pipeline.fit(train_x, train_y)\n",
    "\n",
    "        test_pred = lr_pipeline.predict(test_x)\n",
    "        test_output_eval = evaluate_model(test_y, test_pred)\n",
    "        mlflow.log_metrics(test_output_eval)\n",
    "        # mlflow.sklearn.log_model(lr_pipeline, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('model', 'DecisionTree')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        pipeline = make_pipeline(DictVectorizer(sparse=False),\n",
    "                                DecisionTreeClassifier(**params))\n",
    "        pipeline.fit(train_x, train_y)\n",
    "\n",
    "        prediction = pipeline.predict(test_x)\n",
    "        prediction_eval = evaluate_model(test_y, prediction)   \n",
    "        \n",
    "        mlflow.log_metrics(prediction_eval)\n",
    "        # mlflow.sklearn.log_model(pipeline, artifact_path=\"models_mlflow\")\n",
    "        \n",
    "    return {\"loss\": -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "space = {\"max_depth\": hp.randint(\"max_depth\", 1, 15),\n",
    "        'min_samples_split': hp.randint(\"min_samples_split\", 2, 15),\n",
    "        'min_samples_leaf': hp.randint(\"min_samples_leaf\", 1, 15),\n",
    "        \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        }\n",
    "\n",
    "best_result = fmin(fn= objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=50,\n",
    "                    trials=Trials()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('model', 'RandonForest')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        pipeline = make_pipeline(DictVectorizer(sparse=False),\n",
    "                                RandomForestClassifier(**params))\n",
    "        pipeline.fit(train_x, train_y)\n",
    "\n",
    "        prediction = pipeline.predict(test_x)\n",
    "        prediction_eval = evaluate_model(test_y, prediction) \n",
    "\n",
    "        mlflow.log_metrics(prediction_eval)\n",
    "        # mlflow.sklearn.log_model(pipeline, artifact_path=\"models_mlflow\")\n",
    "        \n",
    "    return {\"loss\": -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "space = {\"n_estimators\": hp.choice(\"n_estimators\", [2,5,10, 20, 30, 50, 100,]),\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 5)),\n",
    "            #'min_samples_split': hp.randint(\"min_samples_split\", 2, 15),\n",
    "           # 'min_samples_leaf': hp.randint(\"min_samples_leaf\", 1, 15),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            }\n",
    "\n",
    "best_result = fmin(fn=random_forest_objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=50,\n",
    "                    trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTrainer():\n",
    "    def __init__(self, params, num_boost_round=1000, early_stopping_rounds=50):\n",
    "        self.params = params\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.booster = None\n",
    "        self.dict_vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Assuming X, y are your training data and labels\n",
    "        # Convert the input features to a sparse matrix using DictVectorizer\n",
    "        \n",
    "        X_sparse = self.dict_vectorizer.fit_transform(X)\n",
    "\n",
    "        # Create xgb.DMatrix\n",
    "        dtrain = xgb.DMatrix(X_sparse, label=y)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        self.booster = xgb.train(self.params,\n",
    "                                 dtrain=dtrain,\n",
    "                                 num_boost_round=self.num_boost_round,\n",
    "                                 early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                 evals=[(dtrain, 'train')],\n",
    "                                 verbose_eval=50)\n",
    "        # mlflow.xgboost.log_model(self.booster, artifact_path='models_mlflow')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert the input features to a sparse matrix using DictVectorizer\n",
    "        X_sparse = self.dict_vectorizer.transform(X)\n",
    "\n",
    "        # Create xgb.DMatrix\n",
    "        dmatrix = xgb.DMatrix(X_sparse)\n",
    "\n",
    "        # Use the trained model for predictions\n",
    "        predictions = self.booster.predict(dmatrix)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag(\"model\", \"Xgboost\")\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        booster =  make_pipeline(XGBoostTrainer(params = params))\n",
    "        \n",
    "        booster.fit(train_x, train_y)\n",
    "        prediction = booster.predict(test_x)\n",
    "        prediction = (prediction >= 0.5).astype('int')\n",
    "        \n",
    "        prediction_eval = evaluate_model(test_y, prediction)  \n",
    "        mlflow.log_metrics(prediction_eval)\n",
    "        \n",
    "\n",
    "    return {'loss': -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 3)),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "            'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "            'objective': 'binary:logistic',  \n",
    "            'eval_metric': 'logloss',                                             \n",
    "            'seed': 42\n",
    "                }\n",
    "\n",
    "best_result = fmin(\n",
    "                fn= objective,\n",
    "                space=search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=Trials()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo $PWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prefect==2.14.9 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///../../databases/mlflow.db\"\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string=\"metrics.f1_score >0.595\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.f1_score ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, F1 Score: {run.data.metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"Custormer-churn-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Custormer-churn-models\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 5\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "new_stage = 'Staging'\n",
    "version = 5\n",
    "date = datetime.today().date() \n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=version,\n",
    "    description=f\"The model version {version}  was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
