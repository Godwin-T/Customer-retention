{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] =\"\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain import ConversationChain\n",
    "from langchain.agents import initialize_agent, load_tools, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "from langchain.document_loaders import HNLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model = 'text-davinci-003',temperature = 0.5)\n",
    "text = \"what do you think about God?\"\n",
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_serially(text):\n",
    "    for _ in range(10):\n",
    "        output = llm.invoke(text)\n",
    "        print(output)\n",
    "\n",
    "async def generate_async(text):\n",
    "    output = await llm.ainvoke(text)\n",
    "    print(output)\n",
    "\n",
    "async def generate_concurrently(text):\n",
    "    task = [generate_async(text) for _ in range(10)]\n",
    "    await asyncio.gather(*task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_serially(text)\n",
    "#await generate_concurrently(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables= [\"name\", \"age\"],\n",
    "                        template = \"What are the characterics of a someone around the age of {age} living {name}\")\n",
    "print(llm.invoke(prompt.format(name = 'califonia', age = 34)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables = [\"adjective\"],\n",
    "                        template = \"What are some common characteristics of {adjective}\")\n",
    "print(llm.invoke(prompt.format(adjective = \"God\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables= [\"description\"],\n",
    "                        template = \"We are a telecommunication company and we are trying to prevent customers from churning\\\n",
    "                            . Generate a promotional mail for one of our customer using information in {description} as \\\n",
    "                                context and it should have a subject relating to the context\")\n",
    "context = \"Generate a mail for one of our customers in a relationship informing them of a network upgrade coming to the area soon\"\n",
    "print(llm.invoke(prompt.format(description = context)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run(\"fish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(['serpapi', 'llm-math'], llm=llm)\n",
    "agent = initialize_agent(tools, llm, \n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
    "agent.invoke(\"who is the current leader of Japan? What is the larget prime number that is smaller than the president age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(llm = llm, verbose = True)\n",
    "conversation.invoke(input = \"Hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.invoke(input = \"i'm doinf fine. How are you doing yourself\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"input\", \"output\"],\n",
    "    template = \"A {input} if to a {output}\"\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\":\"pilot\", \"output\":\"plane\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = SemanticSimilarityExampleSelector.from_examples(examples,\n",
    "                                                           OpenAIEmbeddings(),\n",
    "                                                           FAISS,\n",
    "                                                           k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=selector,\n",
    "    example_prompt=prompt,\n",
    "    prefix=\"Give the location an item can be found\",\n",
    "    suffix = \"input: {noun}\\n output:\",\n",
    "    input_variables=['noun']\n",
    ")\n",
    "\n",
    "noun = \"student\"\n",
    "print(llm.invoke(similar_prompt.format(noun = noun)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(similar_prompt.format(noun = noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(text, embedding = embeddings)\n",
    "retrieval = db.as_retriever()\n",
    "embedding_list = embeddings.embed_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "llm = ChatOpenAI(temperature = 0.5)\n",
    "\n",
    "user_input = input(\"Enter your message:\",)\n",
    "for i in range(5):\n",
    "\n",
    "    chat_history.add_user_message(user_input)\n",
    "    response = llm(chat_history.messages)\n",
    "    print(user_input)\n",
    "    print(response.content)\n",
    "    chat_history.add_ai_message(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = ChatMessageHistory()\n",
    "history.add_ai_message()\n",
    "history.add_user_message()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
