{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import hp, STATUS_OK, fmin, Trials, tpe\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/15 17:31:26 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2025/01/15 17:31:26 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2025/01/15 17:31:28 INFO mlflow.tracking.fluent: Experiment with name 'Customer_Churn_Predictions' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/fresh/Documents/Workflow/Customer-retention/notebooks/mlruns/1', creation_time=1736958688074, experiment_id='1', last_update_time=1736958688074, lifecycle_stage='active', name='Customer_Churn_Predictions', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('sqlite:///mlflow1.db')\n",
    "mlflow.set_experiment('Customer_Churn_Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phoneservice</th>\n",
       "      <th>multiplelines</th>\n",
       "      <th>internetservice</th>\n",
       "      <th>onlinesecurity</th>\n",
       "      <th>onlinebackup</th>\n",
       "      <th>deviceprotection</th>\n",
       "      <th>techsupport</th>\n",
       "      <th>streamingtv</th>\n",
       "      <th>streamingmovies</th>\n",
       "      <th>contract</th>\n",
       "      <th>paperlessbilling</th>\n",
       "      <th>paymentmethod</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no_phone_service</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic_check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>one_year</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed_check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed_check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no_phone_service</td>\n",
       "      <td>dsl</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>one_year</td>\n",
       "      <td>no</td>\n",
       "      <td>bank_transfer_(automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>fiber_optic</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic_check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  seniorcitizen partner dependents  tenure phoneservice  \\\n",
       "0  female              0     yes         no       1           no   \n",
       "1    male              0      no         no      34          yes   \n",
       "2    male              0      no         no       2          yes   \n",
       "3    male              0      no         no      45           no   \n",
       "4  female              0      no         no       2          yes   \n",
       "\n",
       "      multiplelines internetservice onlinesecurity onlinebackup  \\\n",
       "0  no_phone_service             dsl             no          yes   \n",
       "1                no             dsl            yes           no   \n",
       "2                no             dsl            yes          yes   \n",
       "3  no_phone_service             dsl            yes           no   \n",
       "4                no     fiber_optic             no           no   \n",
       "\n",
       "  deviceprotection techsupport streamingtv streamingmovies        contract  \\\n",
       "0               no          no          no              no  month-to-month   \n",
       "1              yes          no          no              no        one_year   \n",
       "2               no          no          no              no  month-to-month   \n",
       "3              yes         yes          no              no        one_year   \n",
       "4               no          no          no              no  month-to-month   \n",
       "\n",
       "  paperlessbilling              paymentmethod  monthlycharges  totalcharges  \\\n",
       "0              yes           electronic_check           29.85         29.85   \n",
       "1               no               mailed_check           56.95       1889.50   \n",
       "2              yes               mailed_check           53.85        108.15   \n",
       "3               no  bank_transfer_(automatic)           42.30       1840.75   \n",
       "4              yes           electronic_check           70.70        151.65   \n",
       "\n",
       "   churn  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/churn-data/processed_data/churn.csv'\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "seniorcitizen       0\n",
       "partner             0\n",
       "dependents          0\n",
       "tenure              0\n",
       "phoneservice        0\n",
       "multiplelines       0\n",
       "internetservice     0\n",
       "onlinesecurity      0\n",
       "onlinebackup        0\n",
       "deviceprotection    0\n",
       "techsupport         0\n",
       "streamingtv         0\n",
       "streamingmovies     0\n",
       "contract            0\n",
       "paperlessbilling    0\n",
       "paymentmethod       0\n",
       "monthlycharges      0\n",
       "totalcharges        0\n",
       "churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "female    3483\n",
       "male      3549\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby([\"gender\"])['churn'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "churn\n",
       "0    5163\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seniorcitizen\n",
       "0    5890\n",
       "1    1142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"seniorcitizen\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['churn']\n",
    "X = data.drop(['churn'], axis=1)\n",
    "X = X.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "(train_x, test_x, \n",
    "    train_y, test_y) = train_test_split(X, y, test_size= 0.3, random_state=1993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)\n",
    "\n",
    "    out = {\"accuracy_score\" : accuracy, \n",
    "            \"precision_score\" :precision, \n",
    "            \"recall_score\" : recall, \n",
    "            \"f1_score\" : f1score}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "c_values = range(1, 50, 5)\n",
    "for val in c_values:\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('model', 'Logistic Regression')\n",
    "        mlflow.log_param('C', val)\n",
    "\n",
    "        lr_pipeline = make_pipeline(DictVectorizer(sparse= False),\n",
    "                                    LogisticRegression(C =val))\n",
    "        lr_pipeline.fit(train_x, train_y)\n",
    "\n",
    "        test_pred = lr_pipeline.predict(test_x)\n",
    "        test_output_eval = evaluate_model(test_y, test_pred)\n",
    "        mlflow.log_metrics(test_output_eval)\n",
    "        # mlflow.sklearn.log_model(lr_pipeline, artifact_path=\"models_mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('model', 'DecisionTree')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        pipeline = make_pipeline(DictVectorizer(sparse=False),\n",
    "                                DecisionTreeClassifier(**params))\n",
    "        pipeline.fit(train_x, train_y)\n",
    "\n",
    "        prediction = pipeline.predict(test_x)\n",
    "        prediction_eval = evaluate_model(test_y, prediction)   \n",
    "        \n",
    "        mlflow.log_metrics(prediction_eval)\n",
    "        # mlflow.sklearn.log_model(pipeline, artifact_path=\"models_mlflow\")\n",
    "        \n",
    "    return {\"loss\": -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "space = {\"max_depth\": hp.randint(\"max_depth\", 1, 15),\n",
    "        'min_samples_split': hp.randint(\"min_samples_split\", 2, 15),\n",
    "        'min_samples_leaf': hp.randint(\"min_samples_leaf\", 1, 15),\n",
    "        \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        }\n",
    "\n",
    "best_result = fmin(fn= objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=50,\n",
    "                    trials=Trials()\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('model', 'RandonForest')\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        pipeline = make_pipeline(DictVectorizer(sparse=False),\n",
    "                                RandomForestClassifier(**params))\n",
    "        pipeline.fit(train_x, train_y)\n",
    "\n",
    "        prediction = pipeline.predict(test_x)\n",
    "        prediction_eval = evaluate_model(test_y, prediction) \n",
    "\n",
    "        mlflow.log_metrics(prediction_eval)\n",
    "        # mlflow.sklearn.log_model(pipeline, artifact_path=\"models_mlflow\")\n",
    "        \n",
    "    return {\"loss\": -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "space = {\"n_estimators\": hp.choice(\"n_estimators\", [2,5,10, 20, 30, 50, 100,]),\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 5)),\n",
    "            #'min_samples_split': hp.randint(\"min_samples_split\", 2, 15),\n",
    "           # 'min_samples_leaf': hp.randint(\"min_samples_leaf\", 1, 15),\n",
    "            \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "            }\n",
    "\n",
    "best_result = fmin(fn=random_forest_objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=50,\n",
    "                    trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTrainer():\n",
    "    def __init__(self, params, num_boost_round=1000, early_stopping_rounds=50):\n",
    "        self.params = params\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.booster = None\n",
    "        self.dict_vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Assuming X, y are your training data and labels\n",
    "        # Convert the input features to a sparse matrix using DictVectorizer\n",
    "        \n",
    "        X_sparse = self.dict_vectorizer.fit_transform(X)\n",
    "\n",
    "        # Create xgb.DMatrix\n",
    "        dtrain = xgb.DMatrix(X_sparse, label=y)\n",
    "\n",
    "        # Train the XGBoost model\n",
    "        self.booster = xgb.train(self.params,\n",
    "                                 dtrain=dtrain,\n",
    "                                 num_boost_round=self.num_boost_round,\n",
    "                                 early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                 evals=[(dtrain, 'train')],\n",
    "                                 verbose_eval=50)\n",
    "        # mlflow.xgboost.log_model(self.booster, artifact_path='models_mlflow')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Convert the input features to a sparse matrix using DictVectorizer\n",
    "        X_sparse = self.dict_vectorizer.transform(X)\n",
    "\n",
    "        # Create xgb.DMatrix\n",
    "        dmatrix = xgb.DMatrix(X_sparse)\n",
    "\n",
    "        # Use the trained model for predictions\n",
    "        predictions = self.booster.predict(dmatrix)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag(\"model\", \"Xgboost\")\n",
    "        \n",
    "        mlflow.log_params(params)\n",
    "        \n",
    "        booster =  make_pipeline(XGBoostTrainer(params = params))\n",
    "        \n",
    "        booster.fit(train_x, train_y)\n",
    "        prediction = booster.predict(test_x)\n",
    "        prediction = (prediction >= 0.5).astype('int')\n",
    "        \n",
    "        prediction_eval = evaluate_model(test_y, prediction)  \n",
    "        mlflow.log_metrics(prediction_eval)\n",
    "        \n",
    "\n",
    "    return {'loss': -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "search_space = {\n",
    "            'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 3)),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "            'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "            'objective': 'binary:logistic',  \n",
    "            'eval_metric': 'logloss',                                             \n",
    "            'seed': 42\n",
    "                }\n",
    "\n",
    "best_result = fmin(\n",
    "                fn= objective,\n",
    "                space=search_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=Trials()\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = \"sqlite:///../../databases/mlflow.db\"\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string=\"metrics.f1_score >0.595\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.f1_score ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, F1 Score: {run.data.metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    mlflow.register_model(model_uri=model_uri, name=\"Custormer-churn-models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Custormer-churn-models\"\n",
    "latest_versions = client.get_latest_versions(name=model_name)\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version = 5\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "new_stage = 'Staging'\n",
    "version = 5\n",
    "date = datetime.today().date() \n",
    "\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=version,\n",
    "    description=f\"The model version {version}  was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
