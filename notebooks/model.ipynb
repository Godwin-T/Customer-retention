{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt import hp, STATUS_OK, fmin, Trials, tpe\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import (precision_score, recall_score,\n",
    "                             f1_score, accuracy_score)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../configs/params.yaml\") as config:\n",
    "    configurations = yaml.safe_load(config)\n",
    "    \n",
    "model_name = configurations[\"base\"]['model']\n",
    "seed = configurations[\"base\"]['random_state']\n",
    "developer = configurations['base']['developer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(configurations[\"tracking\"][\"tracking_url\"])\n",
    "mlflow.set_experiment(configurations[\"tracking\"][\"experiment_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(configurations['data']['data_path'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_training_data(data):\n",
    "\n",
    "    dframe = data.copy()\n",
    "    y = dframe['churn']\n",
    "    X = dframe.drop(['churn'], axis=1)\n",
    "    X = X.to_dict(orient=\"records\")\n",
    "\n",
    "    output_dframe = train_test_split(X, y, test_size= configurations['data']['test_size'], \n",
    "                                            random_state= seed)\n",
    "    return output_dframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, test_x, \n",
    "        train_y, test_y) = process_training_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)\n",
    "\n",
    "    out = {\"accuracy_score\" : accuracy, \n",
    "            \"precision_score\" :precision, \n",
    "            \"recall_score\" : recall, \n",
    "            \"f1_score\" : f1score}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Model\n",
    "\n",
    "def linear_model():\n",
    "\n",
    "    lr_params = configurations['hyperparameters']['linear_model']\n",
    "    c_values = range(lr_params['min_c'], lr_params['max_c'], lr_params['interval'])\n",
    "    artifact_path = f\"{configurations['base']['artifact_path']}/models\"\n",
    "\n",
    "    for val in c_values:\n",
    "    \n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag('developer', developer)\n",
    "            mlflow.set_tag('model_name', \"linear Regression\")\n",
    "            mlflow.log_param('c', val)\n",
    "\n",
    "            lr_pipeline = make_pipeline(DictVectorizer(sparse= False),\n",
    "                                        LogisticRegression(C =val))\n",
    "            lr_pipeline.fit(train_x, train_y)\n",
    "\n",
    "            test_pred = lr_pipeline.predict(test_x)\n",
    "            test_output_eval = evaluate_model(test_y, test_pred)\n",
    "            mlflow.log_metrics(test_output_eval)\n",
    "            mlflow.sklearn.log_model(lr_pipeline, artifact_path=artifact_path)\n",
    "    print(\"Successfully Trained Linear Regression Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree():\n",
    "    def __init__(self, configurations):\n",
    "        self.config = configurations\n",
    "        \n",
    "    def objective(self, params):\n",
    "\n",
    "\n",
    "        model_name = params[\"model_name\"]\n",
    "        del params[\"model_name\"]\n",
    "        with mlflow.start_run():\n",
    "            mlflow.set_tag('developer', developer)\n",
    "            mlflow.set_tag('model_name', model_name)\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            if (model_name == \"decisiontree\"):\n",
    "                pipeline = make_pipeline(DictVectorizer(sparse=False),\n",
    "                                        DecisionTreeClassifier(**params))  \n",
    "                              \n",
    "            elif (model_name == \"randomforest\"):\n",
    "                pipeline = make_pipeline(DictVectorizer(sparse=False),\n",
    "                                RandomForestClassifier(**params))\n",
    "                \n",
    "            else:\n",
    "                print(f\"{model_name} does not exist in models\")\n",
    "\n",
    "            pipeline.fit(train_x, train_y)\n",
    "            prediction = pipeline.predict(test_x)\n",
    "            prediction_eval = evaluate_model(test_y, prediction)   \n",
    "            \n",
    "            mlflow.log_metrics(prediction_eval)\n",
    "            # mlflow.sklearn.log_model(pipeline, artifact_path=\"models_mlflow\")\n",
    "            \n",
    "        return {\"loss\": -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "    \n",
    "\n",
    "    def inference(self, model_name):\n",
    "\n",
    "        criterion = self.config['criterion']\n",
    "        min_depth, max_depth = self.config['min_depth'], self.config['max_depth']\n",
    "        min_samples_split, max_samples_split = self.config['min_sample_split'], self.config['max_sample_split']\n",
    "        min_samples_leaf, max_sample_leaf = self.config['min_sample_leaf'], self.config['max_sample_leaf']\n",
    "\n",
    "        space = {\"max_depth\": hp.randint(\"max_depth\", min_depth, max_depth),\n",
    "                'min_samples_split': hp.randint(\"min_samples_split\", min_samples_split, max_samples_split),\n",
    "                'min_samples_leaf': hp.randint(\"min_samples_leaf\", min_samples_leaf, max_sample_leaf),\n",
    "                \"criterion\": hp.choice(\"criterion\", criterion),\n",
    "                \"model_name\": model_name\n",
    "                }\n",
    "\n",
    "        best_result = fmin(fn= self.objective,\n",
    "                            space=space,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=50,\n",
    "                            trials=Trials()\n",
    "                            )\n",
    "        \n",
    "        return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost():\n",
    "\n",
    "    def __init__(self, params, num_boost_round=1000, early_stopping_rounds=50):\n",
    "        self.params = params\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.booster = None\n",
    "        self.vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        \n",
    "        X_sparse = self.vectorizer.fit_transform(x)\n",
    "\n",
    "        # Create xgb.DMatrix\n",
    "        dtrain = xgb.DMatrix(X_sparse, label=y)\n",
    "        self.booster = xgb.train(self.params,\n",
    "                                 dtrain=dtrain,\n",
    "                                 num_boost_round=self.num_boost_round,\n",
    "                                 early_stopping_rounds=self.early_stopping_rounds,\n",
    "                                 evals=[(dtrain, 'train')],\n",
    "                                 verbose_eval=50)\n",
    "        # mlflow.xgboost.log_model(self.booster, artifact_path='models_mlflow')\n",
    "            \n",
    "    def objective(self, params):\n",
    "\n",
    "        model_name = params[\"model_name\"]\n",
    "        del params[\"model_name\"]\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            mlflow.set_tag('Developer', developer)\n",
    "            mlflow.set_tag(\"model\", model_name)\n",
    "            mlflow.log_params(params)\n",
    "                        \n",
    "            self.fit(train_x, train_y)\n",
    "            prediction = self.predict(test_x)\n",
    "            prediction = (prediction >= 0.5).astype('int')\n",
    "            \n",
    "            prediction_eval = evaluate_model(test_y, prediction)  \n",
    "            mlflow.log_metrics(prediction_eval)\n",
    "        return {'loss': -prediction_eval['f1_score'], 'status': STATUS_OK}\n",
    "\n",
    "    def inference(self, model_name):\n",
    "\n",
    "        objective = self.params['objective']\n",
    "        metric = self.params[\"eval_metric\"]\n",
    "        min_learning_rate = self.params[\"min_learning_rate\"]\n",
    "        max_learning_rate = self.params[\"max_learning_rate\"]\n",
    "        min_depth, max_depth = self.params['min_depth'], self.params['max_depth']\n",
    "        min_child_weight, max_child_weight = self.params['min_child_weight'], self.params['max_child_weight']\n",
    "        \n",
    "        search_space = {\n",
    "                'max_depth': scope.int(hp.quniform('max_depth', min_depth, max_depth, 3)),\n",
    "                'learning_rate': hp.loguniform('learning_rate', min_learning_rate, max_learning_rate),\n",
    "                'min_child_weight': hp.loguniform('min_child_weight', min_child_weight, max_child_weight),\n",
    "                'objective': objective,  \n",
    "                'eval_metric': metric,                                             \n",
    "                'seed': seed,\n",
    "                \"model_name\": model_name\n",
    "                    }\n",
    "\n",
    "        best_result = fmin(fn= self.objective,\n",
    "                            space=search_space,\n",
    "                            algo=tpe.suggest,\n",
    "                            max_evals=50,\n",
    "                            trials=Trials()\n",
    "                            )\n",
    "        return best_result\n",
    "    \n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_sparse = self.vectorizer.transform(X)\n",
    "\n",
    "        # Create xgb.DMatrix\n",
    "        dmatrix = xgb.DMatrix(X_sparse)\n",
    "\n",
    "        # Use the trained model for predictions\n",
    "        predictions = self.booster.predict(dmatrix)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = configurations['hyperparameters']['tree_models']\n",
    "models = configurations['base']['model']\n",
    "\n",
    "\n",
    "tree = Tree(params)\n",
    "result = tree.inference(\"randomforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = configurations['hyperparameters']['xgboost']\n",
    "\n",
    "xgboost = XGBoost(params)\n",
    "result = xgboost.inference(\"xgboost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import pandas as pd\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///../databases/mlflow.db\"\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Store results\n",
    "run_data = []\n",
    "\n",
    "def extract_top_5():\n",
    "\n",
    "    # Get all experiments\n",
    "    experiments = client.search_experiments()\n",
    "    for experiment in experiments:\n",
    "        experiment_id = experiment.experiment_id\n",
    "        \n",
    "        # Get runs for the current experiment\n",
    "        runs = client.search_runs(\n",
    "            experiment_ids=[experiment_id],\n",
    "            filter_string=\"\",\n",
    "            run_view_type=ViewType.ACTIVE_ONLY\n",
    "        )\n",
    "        \n",
    "        for run in runs:\n",
    "            metrics = run.data.metrics\n",
    "            inference_time = (run.info.end_time - run.info.start_time) / 1000\n",
    "           # try:\n",
    "            run_data.append({\n",
    "                \"run_id\": run.info.run_id,  # This was missing in your second code block\n",
    "                \"experiment_id\": experiment_id,\n",
    "                \"f1_score\": metrics.get(\"f1_score\", 0),\n",
    "                \"accuracy_score\": metrics.get(\"accuracy_score\", 0),\n",
    "                \"precision_score\": metrics.get(\"precision_score\", 0),\n",
    "                \"recall_score\": metrics.get(\"recall_score\", 0),\n",
    "                \"inference_time\": inference_time,\n",
    "                \"params\": run.data.params,\n",
    "                \"tags\": run.data.tags.get(\"model_name\", \"unknown\")\n",
    "                })\n",
    "            # except Exception as e:\n",
    "            #     print(f\"Error processing run {run.info.run_id}: {e}\")\n",
    "            #     continue\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(run_data)\n",
    "    print(df.shape)\n",
    "\n",
    "    if not df.empty:\n",
    "        # Sort by f1_score (descending) and inference_time (ascending)\n",
    "        df_sorted = df.sort_values(by=[\"f1_score\", \"inference_time\"], ascending=[False, True])\n",
    "        \n",
    "        # Get top 5 run IDs\n",
    "        top_5_runs = df_sorted.head(5)[\"run_id\"].tolist()\n",
    "        \n",
    "        # Get all run IDs\n",
    "        all_run_ids = df[\"run_id\"].tolist()\n",
    "        \n",
    "        # Runs to delete (not in top 5)\n",
    "        runs_to_delete = set(all_run_ids) - set(top_5_runs)\n",
    "        \n",
    "        # Delete unwanted runs\n",
    "        for run_id in runs_to_delete:\n",
    "            client.delete_run(run_id)\n",
    "        \n",
    "        print(f\"Deleted {len(runs_to_delete)} runs, keeping only the top 5.\")\n",
    "    else:\n",
    "        print(\"No runs found.\")\n",
    "    return df\n",
    "\n",
    "df = extract_top_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_model(modelname, run_id):\n",
    "\n",
    "    # Register the logged model in the Model Registry\n",
    "    model_uri = f\"runs:/{run_id}/models_mlflow\"\n",
    "    registered_model = client.create_registered_model(name=modelname)\n",
    "    client.create_model_version(name=modelname, source=model_uri, run_id=run_id)\n",
    "    print(f\"Model registered successfully!\")\n",
    "\n",
    "def model_transition(modelname, modelid, currentstage=None, newstage=None, modelversion=None):\n",
    "    \"\"\"\n",
    "    Transitions a model to a new stage. If no model is in production, it tags the latest version as 'Production' directly.\n",
    "    \n",
    "    :param modelname: Name of the registered model.\n",
    "    :param currentstage: The current stage of the model (if applicable).\n",
    "    :param newstage: The target stage to transition to.\n",
    "    :param modelversion: The version of the model to transition (if applicable).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if any model is already in Production\n",
    "    try:\n",
    "        production_models = client.get_model_version_by_alias(modelname, \"production\")\n",
    "    except:\n",
    "        production_models =  None \n",
    " \n",
    "    # If no model is in Production, move the latest model to Production\n",
    "\n",
    "    if not production_models:\n",
    "        latest_version = client.get_latest_versions(modelname)[0].version\n",
    "        \n",
    "        # Add a tag to indicate this version is now in Production\n",
    "        client.set_tag(modelid, \"version\", latest_version)       \n",
    "        client.set_registered_model_alias(modelname, \"Production\", latest_version)\n",
    "        \n",
    "        print(f\"Model version {latest_version} transitioned directly to Production.\")\n",
    "        return\n",
    "    \n",
    "    # If a model is already in Production, transition the given version if specified\n",
    "    if currentstage and newstage and modelversion:\n",
    "        client.set_registered_model_alias(modelname, newstage, modelversion)\n",
    "    \n",
    "        print(f\"Model version {modelversion} transitioned from {currentstage} to {newstage}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"sqlite:///../databases/mlflow.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(modelname, alias=\"Production\"):\n",
    "    # Load the model using the alias\n",
    "    model_uri = f\"models:/{modelname}@{alias}\"\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
